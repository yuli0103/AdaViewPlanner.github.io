<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="PAPER_TITLE - AUTHOR_NAMES">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="KEYWORD1, KEYWORD2, KEYWORD3, machine learning, computer vision, AI">
  <!-- TODO: List all authors -->
  <meta name="author" content="FIRST_AUTHOR_NAME, SECOND_AUTHOR_NAME">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="INSTITUTION_OR_LAB_NAME">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="PAPER_TITLE">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="PAPER_TITLE - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="FIRST_AUTHOR_NAME">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="KEYWORD1">
  <meta property="article:tag" content="KEYWORD2">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <!-- TODO: Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE">
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="PAPER_TITLE">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="PAPER_TITLE - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="PAPER_TITLE">
  <meta name="citation_author" content="FIRST_AUTHOR_LAST, FIRST_AUTHOR_FIRST">
  <meta name="citation_author" content="SECOND_AUTHOR_LAST, SECOND_AUTHOR_FIRST">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>PAPER_TITLE - AUTHOR_NAMES | Academic Research</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "PAPER_TITLE",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "FIRST_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      },
      {
        "@type": "Person",
        "name": "SECOND_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>



  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">AdaViewPlanner: Adapting Video Diffusion Models for Viewpoint Planning in 4D Scenes</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="#" target="_blank">Yu Li</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Menghan Xia</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Gongye Liu</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Jianhong Bai</a><sup>4</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Xintao Wang</a><sup>5</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Conglang Zhang</a><sup>6</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Yuxuan Lin</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Ruihang Chu</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Pengfei Wan</a><sup>5</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Yujiu Yang</a><sup>1</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <sup>1</sup>Tsinghua University &nbsp;&nbsp;
                <sup>2</sup>HUST &nbsp;&nbsp;
                <sup>3</sup>HKUST<br>
                <sup>4</sup>Zhejiang University &nbsp;&nbsp;
                <sup>5</sup>Kling Team, Kuaishou Technology &nbsp;&nbsp;
                <sup>6</sup>Wuhan University<br>
              </span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <!-- <span class="link-block">
                <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-file-pdf"></i>
                </span>
                <span>Supplementary</span>
              </a>
            </span> -->

            <span class="link-block">
              <a href="https://github.com/YOUR REPO HERE" target="_blank"
              class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                <i class="fab fa-github"></i>
              </span>
              <span>Code(Coming Soon)</span>
            </a>
          </span>

          <!-- <span class="link-block">
            <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
            class="external-link button is-normal is-rounded is-dark">
            <span class="icon">
              <i class="ai ai-arxiv"></i>
            </span>
            <span>arXiv</span>
          </a>
        </span> -->
      </div>
    </div>
  </div>
</div>
</div>
</div>
</section>


<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- TODO: Replace with your teaser video -->
      <!-- <video poster="" id="tree" autoplay controls muted loop height="100%" preload="metadata">
        <!-- TODO: Add your video file path here -->
        <!-- <source src="static/videos/banner_video.mp4" type="video/mp4">
      </video>
      <!-- TODO: Replace with your video description -->
      <!-- <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section> --> 
<!-- End teaser video -->

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content">
          <!-- Method introduction text -->
          <div class="method-introduction has-text-justified" style="margin-bottom: 2rem;">
            <p>
                <strong>TL;DR:</strong> We propose <span style="font-weight: bold;">AdaViewPlanner</span>, a framework that adapts pre-trained text-to-video models for automatic viewpoint planning in 4D scenes. Given 4D content and text prompts describing the scene context and desired camera motion, our model can generate coordinate-aligned camera pose sequences along with corresponding video visualizations. Leveraging the priors of video generation models, AdaViewPlanner demonstrates strong capability in performing smooth, diverse, instruction-following, and human-centric viewpoint planning within 4D scenes.
            </p>
          </div>
          
          <!-- Method figure -->
          <div class="method-figure">
            <img src="static/images/fig1.png" alt="Method Overview" style="width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);"/>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</section>
    
<!-- Demos Video Carousel Section -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Demos</h2>
      <div id="results-video-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="showcase-video1" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/1.mp4" type="video/mp4">
          </video>
        </div>
        
        <div class="item item-video2">
          <video poster="" id="showcase-video2" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/2.mp4" type="video/mp4">
          </video>
        </div>
        
        <div class="item item-video3">
          <video poster="" id="showcase-video3" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/3.mp4" type="video/mp4">
          </video>
        </div>
        
        <div class="item item-video4">
          <video poster="" id="showcase-video4" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/4.mp4" type="video/mp4">
          </video>
        </div>

        <div class="item item-video5">
          <video poster="" id="showcase-video5" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/5.mp4" type="video/mp4">
          </video>
        </div>

        <div class="item item-video6">
          <video poster="" id="showcase-video6" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/6.mp4" type="video/mp4">
          </video>
        </div>

        <div class="item item-video7">
          <video poster="" id="showcase-video7" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/7.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Demos Video Carousel Section -->

  <!-- Demos Section -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Effect of Random Seeds and Prompts on Camera Generation</h2>
      
      <div class="columns is-multiline is-centered">
        <!-- Video 1: Random Seed -->
        <div class="column is-full">
          <div class="demo-video-wrapper">
            <h3 class="subtitle is-5 has-text-centered">Random Seed</h3>
            <video controls muted loop preload="metadata" class="demo-video">
              <source src="static/videos/8.mp4" type="video/mp4">
            </video>
          </div>
        </div>

        <!-- Video 2: Scene Context Prompt -->
        <div class="column is-full">
          <div class="demo-video-wrapper">
            <h3 class="subtitle is-5 has-text-centered">Scene Context Prompt</h3>
            <video controls muted loop preload="metadata" class="demo-video">
              <source src="static/videos/9.mp4" type="video/mp4">
            </video>
          </div>
        </div>

        <!-- Video 3: Camera Movement Prompt -->
        <div class="column is-full">
          <div class="demo-video-wrapper">
            <h3 class="subtitle is-5 has-text-centered">Camera Movement Prompt</h3>
            <video controls muted loop preload="metadata" class="demo-video">
              <source src="static/videos/8.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>

    </div>
  </div>
</section>

<!-- End Demos Section -->


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Comparisons</h2>
        <div class="content">
          
          <!-- Method figure -->
          <div class="method-figure">
            <img src="static/images/fig5_1.png" alt="Method Overview" style="width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);"/>
          </div>
          
          <!-- Method description text -->
          <div class="method-description has-text-justified" style="margin-top: 2rem;">
            <p>
              Compared with other methods (E.T. [1], DanceCam* [2]), our model generates smoother trajectories that better follow instructions, while also exhibiting a cinematographic style centered on human actions. <br><br>
              [1] Courant, Robin, et al. "ET the Exceptional Trajectories: Text-to-camera-trajectory generation with character awareness." European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2024. <br><br>
              [2] Wang, Zixuan, et al. "Dancecamera3d: 3d camera movement synthesis with music and dance." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2024.
            </p>

          </div>
          
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Additional results</h2>
        <div class="content">
          
          <!-- Method figure -->
          <div class="method-figure">
            <img src="static/images/vis_2.png" alt="Method Overview" style="width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);"/>
          </div>
          
          <!-- Method description text -->
          <div class="method-description has-text-justified" style="margin-top: 2rem;">
            <p>
              The results demonstrate the diversity of the generated trajectories and the model’s ability to follow camera text instructions.
            </p>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Ablation results</h2>
        <div class="content">
          
          <!-- Method figure -->
          <div class="method-figure">
            <img src="static/images/fig5_2.png" alt="Method Overview" style="width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);"/>
          </div>
          
          <!-- Method description text -->
          <div class="method-description has-text-justified" style="margin-top: 2rem;">
            <p>
              Columns 1–4 illustrate the reprojection of 4D human skeletons using the estimated camera parameters, while Column 5 displays the corresponding rendered results in 3D space. We present two ablation variants. <span style="font-style: italic;">w/o Motion</span> refers to the removal of the motion condition in Stage II. Without skeletal references, the model generates smooth but misfocused trajectories, resulting in erroneous viewpoints.  <span style="font-style: italic;">Relative Cam</span> denotes a variant trained without motion conditioning that estimates only relative camera poses, requiring post-processing to align camera and human motion coordinates. While this approach alleviates the viewpoint misalignment, it lacks motion scale awareness, ultimately causing noticeable temporal and spatial inconsistencies.              </p>

          </div>
          
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- TODO: Replace with your paper abstract -->
          <p>
            Recent Text-to-Video (T2V) models have demonstrated powerful capability in visual simulation of real-world geometry and physical laws, indicating its potential as implicit world models. Inspired by this, we explore the feasibility of leveraging the video generation prior for viewpoint planning from given 4D scenes, since videos internally accompany dynamic scenes with natural viewpoints. To this end, we propose a two-stage paradigm to adapt pre-trained T2V models for viewpoint prediction, in a compatible manner. First, we inject the 4D scene representation into the pre-trained T2V model via an adaptive learning branch, where the 4D scene is viewpoint-agnostic and the conditional generated video embeds the viewpoints visually. Then, we formulate viewpoint extraction as a hybrid-condition guided camera extrinsic denoising process. Specifically, a camera extrinsic diffusion branch is further introduced onto the pre-trained T2V model, by taking the generated video and 4D scene as input. Experimental results show the superiority of our proposed method over existing competitors, and ablation studies validate the effectiveness of our key technical designs. To some extent, this work proves the potential of video generation models toward 4D interaction in real world.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Method -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <div class="content">
          <!-- Method introduction text -->
          <div class="method-introduction has-text-justified" style="margin-bottom: 2rem;">
            <p>
              <!-- TODO: Add your method introduction text here -->
            Training over vast amounts of film footage, video generation models can synthesize various dynamic scenes with rich cinematic skills. Based on this observation, we aim to leverage this capability by repurposing these models as virtual cinematographers to design professional camera trajectories for given 4D scenes. For simplicity, we explore and validate this concept by only considering moving human in 4D scenes, which serves as the major context of interest in applications. The overview of the model is depicted below.            </p>
          </div>
          
          <!-- Method figure -->
          <div class="method-figure">
            <img src="static/images/overview_v2.jpg" alt="Method Overview" style="width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);"/>
          </div>
          
          <!-- Method description text -->
          <div class="method-description has-text-justified" style="margin-top: 2rem;">
            <p>
              (a) Stage I model for motion-conditioned cinematic video generation: a pose encoder processes human motion data M from 4D scenes and integrates it with video tokens via spatial motion attention to produce videos with cinematic camera movements. Camera parameters used for guidance are denoted as C. (b) Stage II model: three branches for video, camera, and human motion are combined in an MMDiT framework to extract camera pose.
            </p>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</section>

<!-- End method -->


<!-- Image carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- TODO: Replace with your research result images -->
        <!-- <img src="static/images/carousel1.jpg" alt="First research result visualization" loading="lazy"/>
        <!-- TODO: Replace with description of this result -->
        <!-- <h2 class="subtitle has-text-centered">
          First image description.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <!-- <img src="static/images/carousel2.jpg" alt="Second research result visualization" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Second image description.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <!-- <img src="static/images/carousel3.jpg" alt="Third research result visualization" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
         Third image description.
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <!-- <img src="static/images/carousel4.jpg" alt="Fourth research result visualization" loading="lazy"/>
      <h2 class="subtitle has-text-centered">
        Fourth image description.
      </h2>
    </div>
  </div>
</div>
</div>
</section> -->
<!-- End image carousel -->




<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <!-- <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!-- TODO: Replace with your YouTube video ID -->
            <!-- <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> --> 
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/carousel1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/carousel2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/carousel3.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->





<!-- Paper poster -->
    <!--
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>
 -->

      <!-- TODO: Replace with your poster PDF -->
        <!--

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->





<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{YourPaperKey2024,
  title={Your Paper Title Here},
  author={First Author and Second Author and Third Author},
  journal={Conference/Journal Name},
  year={2024},
  url={https://your-domain.com/your-project-page}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
